# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R948g7WRnXg3Mvou_h75WDM046QYRHSP
"""

# app.py
import os
import numpy as np
import pandas as pd
import streamlit as st
import joblib

from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score, recall_score,
    f1_score, matthews_corrcoef, confusion_matrix, classification_report
)

st.set_page_config(page_title="Telcom Churn Prediction", layout="wide")

st.title("ðŸ“Œ Telco Customer Churn Prediction (BITS ML Assignment-2)")
st.write(
    """
    **Instructions:**
    1) Upload a **CSV file (test data only)**.
    2) Optionally include `Churn` column (Yes/No) to evaluate metrics.
    3) Select a trained model from the dropdown.
    4) Click **Predict** to get outputs.
    """
)

MODEL_DIR = "model"

MODEL_FILES = {
    "Logistic Regression": "logistic_regression.joblib",
    "Decision Tree": "decision_tree.joblib",
    "kNN": "knn.joblib",
    "Naive Bayes (Gaussian)": "naive_bayes_gaussian.joblib",
    "Random Forest": "random_forest.joblib",
    "XGBoost": "xgboost.joblib"
}

def safe_prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    Applies the same minimal cleaning assumptions as training:
    - TotalCharges may contain blanks/spaces -> coerce numeric
    - Drop customerID if present
    Note: Main preprocessing is inside the saved pipeline.
    """
    df = df.copy()

    if "TotalCharges" in df.columns:
        df["TotalCharges"] = pd.to_numeric(df["TotalCharges"].astype(str).str.strip(), errors="coerce")

    if "customerID" in df.columns:
        df = df.drop(columns=["customerID"])

    return df

def get_probabilities(pipeline, X_data):
    if hasattr(pipeline, "predict_proba"):
        return pipeline.predict_proba(X_data)[:, 1]
    if hasattr(pipeline, "decision_function"):
        scores = pipeline.decision_function(X_data)
        return 1 / (1 + np.exp(-scores))
    return pipeline.predict(X_data).astype(float)

uploaded = st.file_uploader("Upload CSV (test data only)", type=["csv"])

col1, col2 = st.columns([1, 2])
with col1:
    model_choice = st.selectbox("Select Model", list(MODEL_FILES.keys()))

with col2:
    st.info(
        "Tip: If your uploaded CSV includes a `Churn` column (Yes/No), the app will show metrics + confusion matrix."
    )

if uploaded is not None:
    try:
        test_df = pd.read_csv(uploaded)
        st.subheader("Preview of uploaded data")
        st.dataframe(test_df.head(20), use_container_width=True)

        test_df = safe_prepare_dataframe(test_df)

        y_available = "Churn" in test_df.columns
        if y_available:
            y_true = test_df["Churn"].map({"No": 0, "Yes": 1})
            if y_true.isna().any():
                st.warning("`Churn` column contains values other than Yes/No. Metrics will be skipped.")
                y_available = False
            else:
                y_true = y_true.astype(int)
            X_test = test_df.drop(columns=["Churn"])
        else:
            X_test = test_df

        model_path = os.path.join(MODEL_DIR, MODEL_FILES[model_choice])
        if not os.path.exists(model_path):
            st.error(f"Model file not found: {model_path}. Please ensure you trained and saved models into /model/")
            st.stop()

        pipeline = joblib.load(model_path)

        if st.button("Predict"):
            proba = get_probabilities(pipeline, X_test)
            y_pred = (proba >= 0.5).astype(int)

            pred_labels = np.where(y_pred == 1, "Yes", "No")
            out_df = X_test.copy()
            out_df["PredictedChurn"] = pred_labels
            out_df["ChurnProbability(Yes)"] = np.round(proba, 4)

            st.subheader("Predictions")
            st.dataframe(out_df.head(50), use_container_width=True)

            # Summary
            st.subheader("Prediction Summary")
            yes_rate = (y_pred.mean() * 100)
            st.write(f"Predicted churn (Yes) rate: **{yes_rate:.2f}%**")
            st.write(out_df["PredictedChurn"].value_counts())

            # Metrics if y available
            if y_available:
                st.subheader("Evaluation Metrics (because `Churn` is available)")
                auc = roc_auc_score(y_true, proba)
                metrics = {
                    "Accuracy": accuracy_score(y_true, y_pred),
                    "AUC": auc,
                    "Precision": precision_score(y_true, y_pred, zero_division=0),
                    "Recall": recall_score(y_true, y_pred, zero_division=0),
                    "F1": f1_score(y_true, y_pred, zero_division=0),
                    "MCC": matthews_corrcoef(y_true, y_pred)
                }
                st.json({k: round(v, 4) for k, v in metrics.items()})

                st.subheader("Confusion Matrix")
                cm = confusion_matrix(y_true, y_pred)
                cm_df = pd.DataFrame(cm, index=["Actual No", "Actual Yes"], columns=["Pred No", "Pred Yes"])
                st.dataframe(cm_df, use_container_width=True)

                st.subheader("Classification Report")
                report = classification_report(y_true, y_pred, digits=4)
                st.code(report)

            else:
                st.warning("No valid `Churn` column found â†’ showing prediction outputs only.")

    except Exception as e:
        st.error("Something went wrong while processing the uploaded file.")
        st.exception(e)
else:
    st.warning("Please upload a CSV file to begin.")